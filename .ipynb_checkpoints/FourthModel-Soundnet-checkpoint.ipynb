{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, CuDNNLSTM, Multiply,Dropout\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#address to getData->output folder\n",
    "address = \"C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\data_soundnet\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(id):\n",
    "    with open(address + f'y_train_{id}','rb') as f:\n",
    "        y_train=np.array(pickle.load(f))\n",
    "    with open(address+f'y_test_{id}','rb') as f:\n",
    "        y_test=np.array(pickle.load(f))\n",
    "    with open(address+ f'X_train_{id}','rb') as f:\n",
    "        X_train = np.array(pickle.load(f))\n",
    "    with open(address+f'X_test_{id}','rb') as f:\n",
    "        X_test = np.array(pickle.load(f))\n",
    "\n",
    "\n",
    "    \n",
    "    print(f'id : {id}')\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    encoder = LabelBinarizer()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "   \n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 1001\n",
      "(7360, 1, 110361)\n",
      "id : 1001\n",
      "Train on 7360 samples, validate on 82 samples\n",
      "Epoch 1/50\n",
      "7360/7360 [==============================] - 51s 7ms/step - loss: 1.7919 - acc: 0.1745 - val_loss: 1.7862 - val_acc: 0.2317\n",
      "Epoch 2/50\n",
      "7360/7360 [==============================] - 46s 6ms/step - loss: 1.7898 - acc: 0.1822 - val_loss: 1.7917 - val_acc: 0.2073\n",
      "Epoch 3/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7863 - acc: 0.1902 - val_loss: 1.8068 - val_acc: 0.1220\n",
      "Epoch 4/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7842 - acc: 0.1938 - val_loss: 1.8021 - val_acc: 0.0976\n",
      "Epoch 5/50\n",
      "7360/7360 [==============================] - 45s 6ms/step - loss: 1.7833 - acc: 0.1985 - val_loss: 1.8130 - val_acc: 0.1341\n",
      "Epoch 6/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7777 - acc: 0.2082 - val_loss: 1.8287 - val_acc: 0.1098\n",
      "Epoch 7/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7781 - acc: 0.2088 - val_loss: 1.8168 - val_acc: 0.1951\n",
      "Epoch 8/50\n",
      "7360/7360 [==============================] - 44s 6ms/step - loss: 1.7742 - acc: 0.2113 - val_loss: 1.8308 - val_acc: 0.0976\n",
      "Epoch 9/50\n",
      "7360/7360 [==============================] - 44s 6ms/step - loss: 1.7734 - acc: 0.2113 - val_loss: 1.8193 - val_acc: 0.14631.7733 - acc: 0\n",
      "Epoch 10/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7696 - acc: 0.2158 - val_loss: 1.8061 - val_acc: 0.1585\n",
      "Epoch 11/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7676 - acc: 0.2212 - val_loss: 1.7942 - val_acc: 0.1585\n",
      "Epoch 12/50\n",
      "7360/7360 [==============================] - 44s 6ms/step - loss: 1.7665 - acc: 0.2220 - val_loss: 1.8089 - val_acc: 0.1707\n",
      "Epoch 13/50\n",
      "7360/7360 [==============================] - 44s 6ms/step - loss: 1.7628 - acc: 0.2296 - val_loss: 1.7872 - val_acc: 0.2439\n",
      "Epoch 14/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7667 - acc: 0.2246 - val_loss: 1.7956 - val_acc: 0.2073\n",
      "Epoch 15/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7643 - acc: 0.2216 - val_loss: 1.8222 - val_acc: 0.1463\n",
      "Epoch 16/50\n",
      "7360/7360 [==============================] - 43s 6ms/step - loss: 1.7581 - acc: 0.2300 - val_loss: 1.7950 - val_acc: 0.1463\n",
      "Epoch 17/50\n",
      " 352/7360 [>.............................] - ETA: 41s - loss: 1.7509 - acc: 0.2386"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-4a92e3cadd48>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m#filePath =f'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\ExtendedSavedModels\\\\{i}.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m#checkpoint = ModelCheckpoint(filepath=filePath,monitor='val_acc',mode='max',save_best_only=True,verbose=1,save_weights_only=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms0_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc0_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,callbacks=[checkpoint]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;31m#plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_num_people=[]\n",
    "for i in range(1,92):\n",
    "    if i <10:\n",
    "        total_num_people.append('100'+str(i))\n",
    "    else:\n",
    "        total_num_people.append('10'+str(i))\n",
    "\n",
    "for i in total_num_people:\n",
    "    if True:\n",
    "        X_train=[]\n",
    "        X_test=[]\n",
    "        y_train=[]\n",
    "        y_test=[]\n",
    "        X_train,y_train,X_test,y_test=loadData(i)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "    #load data here\n",
    "    #input_shape = batch_size,time_steps,input_dim\n",
    "\n",
    "    #batch_size = X_train.shape[0]   #automatically taken no need to specify\n",
    "    time_steps = X_train.shape[1]\n",
    "    input_dim = X_train.shape[2]\n",
    "\n",
    "\n",
    "\n",
    "    hid_pre_acts = [16]\n",
    "    hid_post_acts = [96]\n",
    "    #dense1s = [16,32,64,96,128,256]\n",
    "    #dense2s = [16,32,64,96,128,256]\n",
    "    for hid_pre_act in hid_pre_acts:\n",
    "        for hid_post_act in hid_post_acts:\n",
    "            # Defined shared layers as global variables\n",
    "            repeator = RepeatVector(time_steps) #500\n",
    "            concatenator = Concatenate(axis=-1)\n",
    "            densor = Dense(1, activation = \"relu\")\n",
    "            activator = Activation('softmax', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "            dotor = Dot(axes = 1)\n",
    "\n",
    "            #one step attention\n",
    "\n",
    "            def one_step_attention(a,s_prev):\n",
    "\n",
    "                s_prev = repeator(s_prev)\n",
    "                concat = concatenator([a,s_prev])\n",
    "                e = densor(concat)\n",
    "                alphas = activator(e)\n",
    "                K.print_tensor(alphas)\n",
    "                context = dotor([alphas, a])\n",
    "\n",
    "                return context\n",
    "            \n",
    "            post_activation_lstm_cell = CuDNNLSTM(hid_post_act,return_state=True)\n",
    "            #output_layer = Dense(dense1,activation='relu')\n",
    "            #onemore = Dense(dense2,activation='relu')\n",
    "            fin_out = Dense(6,activation='softmax')\n",
    "\n",
    "                # model\n",
    "\n",
    "            def model(time_steps,input_dim,hid_post_act,hid_pre_act):\n",
    "\n",
    "                X = Input(shape =(time_steps,input_dim))\n",
    "                s0 = Input(shape=(hid_post_act,),name='s0')\n",
    "                c0 = Input(shape=(hid_post_act,),name='c0')\n",
    "                s=s0\n",
    "                c=c0\n",
    "                outputs=[]\n",
    "\n",
    "\n",
    "                # Pre-LSTM 16\n",
    "                a = CuDNNLSTM(hid_pre_act,return_sequences=True)(X)\n",
    "                a = Dropout(0.4)(a)\n",
    "                #6 is final output size\n",
    "                for t in range(1):\n",
    "                    context =one_step_attention(a,s)\n",
    "                    s, _, c = post_activation_lstm_cell(context, initial_state=[s, c])\n",
    "                    #out = output_layer(s)\n",
    "                    #o = onemore(out)\n",
    "                    k=fin_out(s)\n",
    "                    outputs.append(k)\n",
    "\n",
    "\n",
    "                model = Model([X, s0, c0], outputs)\n",
    "\n",
    "                return model       \n",
    "\n",
    "            model = model(time_steps,input_dim,hid_post_act,hid_pre_act)\n",
    "\n",
    "            opt = Adam()\n",
    "            #opt = Adam(lr = 0.005, beta_1=0.9, beta_2=0.999, decay = 0.01)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            #model.summary()\n",
    "            #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "            print(X_train.shape)\n",
    "            s0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            c0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            s0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            c0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            print(f'id : {i}')\n",
    "            #filePath =f'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\ExtendedSavedModels\\\\{i}.h5'\n",
    "            #checkpoint = ModelCheckpoint(filepath=filePath,monitor='val_acc',mode='max',save_best_only=True,verbose=1,save_weights_only=False)\n",
    "            model.fit([X_train, s0, c0], y_train, epochs=50,validation_data=([X_test,s0_t,c0_t],y_test)) #,callbacks=[checkpoint]\n",
    "            #plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
