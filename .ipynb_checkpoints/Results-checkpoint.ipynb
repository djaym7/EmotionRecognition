{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.849Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JhMWnun9XH7y"
   },
   "outputs": [],
   "source": [
    "address='D:\\\\data_mfcc\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.855Z"
    }
   },
   "outputs": [],
   "source": [
    "def loadData(id):\n",
    "    with open(address + f'y_train_{id}','rb') as f:\n",
    "        y_train=np.array(pickle.load(f))\n",
    "    with open(address+f'y_test_{id}','rb') as f:\n",
    "        y_test=np.array(pickle.load(f))\n",
    "    with open(address+ f'X_train_{id}','rb') as f:\n",
    "        X_train = np.array(pickle.load(f))\n",
    "    with open(address+f'X_test_{id}','rb') as f:\n",
    "        X_test = np.array(pickle.load(f))\n",
    "\n",
    "    scalers = {}\n",
    "    for k in range(X_train.shape[2]):\n",
    "        scalers[k] = StandardScaler()\n",
    "        X_train[:, k, :] = scalers[k].fit_transform(X_train[:, k, :]) \n",
    "\n",
    "    for j in range(X_test.shape[2]):\n",
    "        X_test[:, j, :] = scalers[j].transform(X_test[:, j, :])\n",
    "    \n",
    "    print(f'id : {id}')\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    encoder = LabelBinarizer()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "   \n",
    "    return X_test,y_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.859Z"
    }
   },
   "outputs": [],
   "source": [
    "def result(y_pred,y_test,plot=False):\n",
    "    y_pred_final=[] #getting final answers \n",
    "    y_test_final=[]\n",
    "    for i in range((y_pred.shape[0])):\n",
    "        y_pred_final.append(np.argmax(y_pred[i]))\n",
    "        y_test_final.append(np.argmax(y_test[i]))\n",
    "\n",
    "    y_pred_final_alpha=[]\n",
    "    y_test_final_alpha=[]\n",
    "\n",
    "\n",
    "    conf_Mat = confusion_matrix(y_test_final,y_pred_final,labels=[0,1,2,3,4,5])\n",
    "    norm_conf_Mat = (conf_Mat / conf_Mat.astype(np.float).sum(axis=1))*100\n",
    "    accuracy = accuracy_score(y_test_final,y_pred_final)\n",
    "    \n",
    "    #plot confusion matrix\n",
    "    #plt.subplot(1,2,1)\n",
    "\n",
    "    if plot == True:\n",
    "        norm_df_cm = pd.DataFrame(norm_conf_Mat, index = ['ANG','DIS','FEA','HAP','NEU','SAD'],\n",
    "                  columns = ['ANG','DIS','FEA','HAP','NEU','SAD'])\n",
    "        df_cm = pd.DataFrame(conf_Mat, index = ['ANG','DIS','FEA','HAP','NEU','SAD'],\n",
    "                  columns = ['ANG','DIS','FEA','HAP','NEU','SAD'])\n",
    "        \n",
    "    return accuracy,norm_df_cm,df_cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.862Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot(df_cm1,df_cm2,id,accuracy_att,accuracy):\n",
    "    fig, (ax1,ax2) =plt.subplots(1,2,figsize=(20,5))\n",
    "    #ax.set_title(id)\n",
    "    ax1.set_title(f'Attention {id} - accuracy - {accuracy_att*100:.2f}')\n",
    "    ax2.set_title(f'Regular {id} - accuracy - {accuracy*100:.2f}')\n",
    "    sn.heatmap(df_cm1, annot=True,ax=ax1,fmt='g')\n",
    "    sn.heatmap(df_cm2, annot=True,ax=ax2,fmt='g')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.864Z"
    }
   },
   "outputs": [],
   "source": [
    "# edit the address to local dir for attention models from fourthmodel.py variable filepath\n",
    "\n",
    "def AttentionModel(X_test,y_test,id):\n",
    "    s0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "    c0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "    model = keras.models.load_model(r\"C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\"+f'/{id}.h5')\n",
    "    return result(model.predict([X_test,s0_t,c0_t]),y_test,plot=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.867Z"
    }
   },
   "outputs": [],
   "source": [
    "# edit the address to local dir for attention models from fourthmodel-NA variable filepath\n",
    "\n",
    "def NonAttentionModel(X_test,y_test,id):\n",
    "    model = keras.models.load_model(r\"C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\"+f'/NA{id}.h5')\n",
    "    return result(model.predict(X_test),y_test,plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.870Z"
    }
   },
   "outputs": [],
   "source": [
    "total_num_people=[]\n",
    "for i in range(1,92):\n",
    "    if i <10:\n",
    "        total_num_people.append('100'+str(i))\n",
    "    else:\n",
    "        total_num_people.append('10'+str(i))\n",
    "hid_post_act = 96\n",
    "att_acc=[]\n",
    "acc=[]\n",
    "att_df_list=[]\n",
    "df_list=[]\n",
    "for i in total_num_people:\n",
    "    \n",
    "    X_test,y_test=loadData(i)\n",
    "    accuracy_att,norm_df_cm1,df_cm1 = AttentionModel(X_test,y_test,i)\n",
    "    #accuracy,norm_df_cm2,df_cm2= NonAttentionModel(X_test,y_test,i)\n",
    "    att_df_list.append(df_cm1)\n",
    "    #df_list.append(df_cm2)\n",
    "    #att_acc.append(accuracy_att)\n",
    "    #acc.append(accuracy)\n",
    "    #plot(norm_df_cm1,norm_df_cm2,i,accuracy_att,accuracy)\n",
    "    \n",
    "    #change the address where you would like to save all images or delete the code below if you dont want image output\n",
    "    #plt.savefig(r\"C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\confusion_matrices\\ \" + f'{i}.png')\n",
    "    plt.close('all')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.875Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy_att,norm_df_cm1,df_cm1 = AttentionModel(X_test,y_test,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.877Z"
    }
   },
   "outputs": [],
   "source": [
    "sn.heatmap(df_cm1, annot=True,ax=ax1,fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.880Z"
    }
   },
   "outputs": [],
   "source": [
    "df_att = pd.DataFrame().reindex_like(att_df_list[0])\n",
    "for i in att_df_list:\n",
    "    df_att=df_att.add(i,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.883Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame().reindex_like(att_df_list[0])\n",
    "for i in df_list:\n",
    "    df=df.add(i,fill_value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.886Z"
    }
   },
   "outputs": [],
   "source": [
    "mean_att_acc = np.array(att_acc).mean()\n",
    "mean_acc = np.array(acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.889Z"
    }
   },
   "outputs": [],
   "source": [
    "print(mean_att_acc,'\\t',mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.891Z"
    }
   },
   "outputs": [],
   "source": [
    "df_att = (df_att / df_att.astype(np.float).sum(axis=1))*100\n",
    "df = (df / df.astype(np.float).sum(axis=1))*100\n",
    "plot(df_att,df,id='aLL',accuracy=mean_acc,accuracy_att=mean_att_acc)\n",
    "plt.savefig(f'all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.894Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = pd.DataFrame(np.array([att_acc,acc]).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.896Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy.plot(figsize=(25,5),fontsize=15,kind='bar')\n",
    "plt.savefig('accuracyBarPlot.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-03-24T23:05:45.899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy.plot(figsize=(25,5),fontsize=15)\n",
    "plt.savefig('accuracyPlot.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
