{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T21:25:04.297972Z",
     "start_time": "2019-03-24T21:24:59.512669Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "bMOFd62wWVO6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import MaxPooling1D,Flatten,Reshape,Bidirectional, Concatenate, Permute, Dot, Input, CuDNNLSTM, Conv1D, Multiply,Dropout,BatchNormalization\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T21:25:04.391879Z",
     "start_time": "2019-03-24T21:25:04.388881Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "JhMWnun9XH7y"
   },
   "outputs": [],
   "source": [
    "address='D:\\\\data_mfcc\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T21:25:04.408889Z",
     "start_time": "2019-03-24T21:25:04.394880Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "V0G0two7WVPL"
   },
   "outputs": [],
   "source": [
    "def loadData(id):\n",
    "    with open(address + f'y_train_{id}','rb') as f:\n",
    "        y_train=np.array(pickle.load(f))\n",
    "    with open(address+f'y_test_{id}','rb') as f:\n",
    "        y_test=np.array(pickle.load(f))\n",
    "    with open(address+ f'X_train_{id}','rb') as f:\n",
    "        X_train = np.array(pickle.load(f))\n",
    "    with open(address+f'X_test_{id}','rb') as f:\n",
    "        X_test = np.array(pickle.load(f))\n",
    "\n",
    "    scalers = {}\n",
    "    for k in range(X_train.shape[2]):\n",
    "        scalers[k] = StandardScaler()\n",
    "        X_train[:, k, :] = scalers[k].fit_transform(X_train[:, k, :]) \n",
    "\n",
    "    for j in range(X_test.shape[2]):\n",
    "        X_test[:, j, :] = scalers[j].transform(X_test[:, j, :])\n",
    "    \n",
    "    print(f'id : {id}')\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    encoder = LabelBinarizer()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "   \n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T22:41:39.418625Z",
     "start_time": "2019-03-24T21:25:56.530677Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9693
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 53391,
     "status": "error",
     "timestamp": 1553114505508,
     "user": {
      "displayName": "",
      "photoUrl": "",
      "userId": ""
     },
     "user_tz": 420
    },
    "id": "vM6Z5_wjWVPW",
    "outputId": "488ff3fc-c0e6-4f92-c80b-8348dfd955ac",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 1001\n",
      "(7360, 499, 13)\n",
      "id : 1001\n",
      "Train on 7360 samples, validate on 82 samples\n",
      "Epoch 1/150\n",
      "7360/7360 [==============================] - 34s 5ms/step - loss: 1.5697 - acc: 0.3568 - val_loss: 1.8116 - val_acc: 0.1951\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.19512, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py:872: UserWarning: Layer cu_dnnlstm_3 was passed non-serializable keyword arguments: {'initial_state': [<tf.Tensor 's0_1:0' shape=(?, 96) dtype=float32>, <tf.Tensor 'c0_1:0' shape=(?, 96) dtype=float32>]}. They will not be included in the serialized model (and thus will be missing at deserialization time).\n",
      "  '. They will not be included '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.4787 - acc: 0.3986 - val_loss: 1.7105 - val_acc: 0.2195\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.19512 to 0.21951, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 3/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.4471 - acc: 0.4155 - val_loss: 1.7086 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.21951 to 0.31707, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 4/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.4176 - acc: 0.4307 - val_loss: 1.6414 - val_acc: 0.2439\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.31707\n",
      "Epoch 5/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3968 - acc: 0.4401 - val_loss: 1.7110 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.31707\n",
      "Epoch 6/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3803 - acc: 0.4433 - val_loss: 1.7332 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.31707\n",
      "Epoch 7/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3677 - acc: 0.4473 - val_loss: 1.8497 - val_acc: 0.2561\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.31707\n",
      "Epoch 8/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3649 - acc: 0.4534 - val_loss: 1.7330 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00008: val_acc did not improve from 0.31707\n",
      "Epoch 9/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3513 - acc: 0.4584 - val_loss: 1.7283 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.31707\n",
      "Epoch 10/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3389 - acc: 0.4690 - val_loss: 1.6180 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00010: val_acc did not improve from 0.31707\n",
      "Epoch 11/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3201 - acc: 0.4705 - val_loss: 1.6995 - val_acc: 0.2561\n",
      "\n",
      "Epoch 00011: val_acc did not improve from 0.31707\n",
      "Epoch 12/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3240 - acc: 0.4757 - val_loss: 1.6584 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.31707\n",
      "Epoch 13/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3172 - acc: 0.4755 - val_loss: 1.7943 - val_acc: 0.2439\n",
      "\n",
      "Epoch 00013: val_acc did not improve from 0.31707\n",
      "Epoch 14/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.3029 - acc: 0.4732 - val_loss: 1.6128 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.31707\n",
      "Epoch 15/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2994 - acc: 0.4817 - val_loss: 1.8907 - val_acc: 0.2439\n",
      "\n",
      "Epoch 00015: val_acc did not improve from 0.31707\n",
      "Epoch 16/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2990 - acc: 0.4870 - val_loss: 1.6726 - val_acc: 0.2317\n",
      "\n",
      "Epoch 00016: val_acc did not improve from 0.31707\n",
      "Epoch 17/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2859 - acc: 0.4904 - val_loss: 1.6917 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.31707\n",
      "Epoch 18/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2745 - acc: 0.4914 - val_loss: 1.6829 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.31707\n",
      "Epoch 19/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2798 - acc: 0.4837 - val_loss: 1.5462 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00019: val_acc improved from 0.31707 to 0.32927, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 20/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2735 - acc: 0.4932 - val_loss: 1.6138 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.32927 to 0.34146, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 21/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2644 - acc: 0.4954 - val_loss: 1.5747 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.34146\n",
      "Epoch 22/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2617 - acc: 0.5033 - val_loss: 1.6215 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00022: val_acc did not improve from 0.34146\n",
      "Epoch 23/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2494 - acc: 0.5091 - val_loss: 1.6912 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.34146\n",
      "Epoch 24/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2340 - acc: 0.5141 - val_loss: 1.4969 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00024: val_acc did not improve from 0.34146\n",
      "Epoch 25/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2336 - acc: 0.5046 - val_loss: 1.6019 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00025: val_acc improved from 0.34146 to 0.36585, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 26/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2381 - acc: 0.5111 - val_loss: 1.6590 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00026: val_acc did not improve from 0.36585\n",
      "Epoch 27/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2262 - acc: 0.5149 - val_loss: 1.5655 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.36585\n",
      "Epoch 28/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2205 - acc: 0.5264 - val_loss: 1.4681 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.36585\n",
      "Epoch 29/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2182 - acc: 0.5254 - val_loss: 1.7012 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.36585\n",
      "Epoch 30/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2066 - acc: 0.5207 - val_loss: 1.6665 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.36585\n",
      "Epoch 31/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2058 - acc: 0.5266 - val_loss: 1.4948 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00031: val_acc did not improve from 0.36585\n",
      "Epoch 32/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2167 - acc: 0.5140 - val_loss: 1.7129 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.36585\n",
      "Epoch 33/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2079 - acc: 0.5213 - val_loss: 1.5542 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.36585\n",
      "Epoch 34/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2061 - acc: 0.5205 - val_loss: 1.6075 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.36585\n",
      "Epoch 35/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.2049 - acc: 0.5273 - val_loss: 1.5671 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.36585\n",
      "Epoch 36/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1989 - acc: 0.5242 - val_loss: 1.4576 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00036: val_acc improved from 0.36585 to 0.39024, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 37/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1989 - acc: 0.5239 - val_loss: 1.4883 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.39024\n",
      "Epoch 38/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1790 - acc: 0.5340 - val_loss: 1.4497 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.39024\n",
      "Epoch 39/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1933 - acc: 0.5253 - val_loss: 1.4942 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.39024\n",
      "Epoch 40/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1862 - acc: 0.5274 - val_loss: 1.6160 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.39024\n",
      "Epoch 41/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1851 - acc: 0.5325 - val_loss: 1.5850 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.39024\n",
      "Epoch 42/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1847 - acc: 0.5310 - val_loss: 1.5889 - val_acc: 0.3415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00042: val_acc did not improve from 0.39024\n",
      "Epoch 43/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1722 - acc: 0.5405 - val_loss: 1.4877 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00043: val_acc improved from 0.39024 to 0.41463, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 44/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1661 - acc: 0.5451 - val_loss: 1.4669 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00044: val_acc improved from 0.41463 to 0.45122, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 45/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1692 - acc: 0.5408 - val_loss: 1.5708 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.45122\n",
      "Epoch 46/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1668 - acc: 0.5412 - val_loss: 1.5328 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.45122\n",
      "Epoch 47/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1692 - acc: 0.5382 - val_loss: 1.4808 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.45122\n",
      "Epoch 48/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1598 - acc: 0.5387 - val_loss: 1.6312 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.45122\n",
      "Epoch 49/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1584 - acc: 0.5383 - val_loss: 1.5116 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.45122\n",
      "Epoch 50/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1548 - acc: 0.5458 - val_loss: 1.6483 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.45122\n",
      "Epoch 51/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1795 - acc: 0.5332 - val_loss: 1.6202 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.45122\n",
      "Epoch 52/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1733 - acc: 0.5337 - val_loss: 1.6829 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.45122\n",
      "Epoch 53/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1597 - acc: 0.5418 - val_loss: 1.6917 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.45122\n",
      "Epoch 54/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1649 - acc: 0.5353 - val_loss: 1.4542 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.45122\n",
      "Epoch 55/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1495 - acc: 0.5420 - val_loss: 1.4352 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.45122\n",
      "Epoch 56/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1458 - acc: 0.5486 - val_loss: 1.7077 - val_acc: 0.3049\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.45122\n",
      "Epoch 57/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1407 - acc: 0.5495 - val_loss: 1.5319 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.45122\n",
      "Epoch 58/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1365 - acc: 0.5535 - val_loss: 1.4957 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.45122\n",
      "Epoch 59/150\n",
      "7360/7360 [==============================] - 31s 4ms/step - loss: 1.1385 - acc: 0.5488 - val_loss: 1.5906 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.45122\n",
      "Epoch 60/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1417 - acc: 0.5530 - val_loss: 1.6935 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00060: val_acc did not improve from 0.45122\n",
      "Epoch 61/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1472 - acc: 0.5486 - val_loss: 1.4850 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.45122\n",
      "Epoch 62/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1341 - acc: 0.5448 - val_loss: 1.4864 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.45122\n",
      "Epoch 63/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1266 - acc: 0.5567 - val_loss: 1.5382 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.45122\n",
      "Epoch 64/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1240 - acc: 0.5590 - val_loss: 1.4997 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.45122\n",
      "Epoch 65/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1468 - acc: 0.5522 - val_loss: 1.4807 - val_acc: 0.4390\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.45122\n",
      "Epoch 66/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1279 - acc: 0.5571 - val_loss: 1.4674 - val_acc: 0.4756\n",
      "\n",
      "Epoch 00066: val_acc improved from 0.45122 to 0.47561, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 67/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1161 - acc: 0.5579 - val_loss: 1.5854 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.47561\n",
      "Epoch 68/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1335 - acc: 0.5549 - val_loss: 1.5130 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.47561\n",
      "Epoch 69/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1331 - acc: 0.5614 - val_loss: 1.5697 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.47561\n",
      "Epoch 70/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1318 - acc: 0.5541 - val_loss: 1.5785 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.47561\n",
      "Epoch 71/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1365 - acc: 0.5481 - val_loss: 1.5073 - val_acc: 0.4390\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.47561\n",
      "Epoch 72/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1297 - acc: 0.5569 - val_loss: 1.5997 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.47561\n",
      "Epoch 73/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1177 - acc: 0.5556 - val_loss: 1.5384 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.47561\n",
      "Epoch 74/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1197 - acc: 0.5649 - val_loss: 1.4570 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.47561\n",
      "Epoch 75/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1220 - acc: 0.5553 - val_loss: 1.4195 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.47561\n",
      "Epoch 76/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1330 - acc: 0.5462 - val_loss: 1.4938 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.47561\n",
      "Epoch 77/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1062 - acc: 0.5639 - val_loss: 1.4388 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.47561\n",
      "Epoch 78/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1280 - acc: 0.5567 - val_loss: 1.4995 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.47561\n",
      "Epoch 79/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1240 - acc: 0.5537 - val_loss: 1.6065 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.47561\n",
      "Epoch 80/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1230 - acc: 0.5632 - val_loss: 1.6845 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.47561\n",
      "Epoch 81/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1121 - acc: 0.5673 - val_loss: 1.5625 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.47561\n",
      "Epoch 82/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1127 - acc: 0.5587 - val_loss: 1.5161 - val_acc: 0.4634\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.47561\n",
      "Epoch 83/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1055 - acc: 0.5624 - val_loss: 1.6800 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.47561\n",
      "Epoch 84/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1165 - acc: 0.5587 - val_loss: 1.5299 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.47561\n",
      "Epoch 85/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1332 - acc: 0.5548 - val_loss: 1.5293 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.47561\n",
      "Epoch 86/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1040 - acc: 0.5692 - val_loss: 1.5386 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.47561\n",
      "Epoch 87/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1103 - acc: 0.5633 - val_loss: 1.4908 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.47561\n",
      "Epoch 88/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1170 - acc: 0.5560 - val_loss: 1.4154 - val_acc: 0.4268\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.47561\n",
      "Epoch 89/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1133 - acc: 0.5586 - val_loss: 1.5573 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.47561\n",
      "Epoch 90/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1172 - acc: 0.5592 - val_loss: 1.5538 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00090: val_acc did not improve from 0.47561\n",
      "Epoch 91/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1221 - acc: 0.5594 - val_loss: 1.5393 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.47561\n",
      "Epoch 92/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1114 - acc: 0.5654 - val_loss: 1.5516 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.47561\n",
      "Epoch 93/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1044 - acc: 0.5689 - val_loss: 1.7315 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.47561\n",
      "Epoch 94/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1200 - acc: 0.5601 - val_loss: 1.5955 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.47561\n",
      "Epoch 95/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1333 - acc: 0.5576 - val_loss: 1.5254 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.47561\n",
      "Epoch 96/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1185 - acc: 0.5592 - val_loss: 1.4105 - val_acc: 0.4390\n",
      "\n",
      "Epoch 00096: val_acc did not improve from 0.47561\n",
      "Epoch 97/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1106 - acc: 0.5628 - val_loss: 1.4899 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.47561\n",
      "Epoch 98/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1083 - acc: 0.5658 - val_loss: 1.5314 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.47561\n",
      "Epoch 99/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1033 - acc: 0.5687 - val_loss: 1.6524 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.47561\n",
      "Epoch 100/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1227 - acc: 0.5549 - val_loss: 1.4839 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.47561\n",
      "Epoch 101/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1209 - acc: 0.5557 - val_loss: 1.6684 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00101: val_acc did not improve from 0.47561\n",
      "Epoch 102/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1068 - acc: 0.5639 - val_loss: 1.6225 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00102: val_acc did not improve from 0.47561\n",
      "Epoch 103/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1186 - acc: 0.5641 - val_loss: 1.8096 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00103: val_acc did not improve from 0.47561\n",
      "Epoch 104/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1118 - acc: 0.5587 - val_loss: 1.4405 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00104: val_acc did not improve from 0.47561\n",
      "Epoch 105/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1096 - acc: 0.5655 - val_loss: 1.5066 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00105: val_acc did not improve from 0.47561\n",
      "Epoch 106/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1117 - acc: 0.5609 - val_loss: 1.6726 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00106: val_acc did not improve from 0.47561\n",
      "Epoch 107/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0859 - acc: 0.5651 - val_loss: 1.5104 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00107: val_acc did not improve from 0.47561\n",
      "Epoch 108/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0907 - acc: 0.5772 - val_loss: 1.6835 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00108: val_acc did not improve from 0.47561\n",
      "Epoch 109/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1106 - acc: 0.5625 - val_loss: 1.6516 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00109: val_acc did not improve from 0.47561\n",
      "Epoch 110/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0810 - acc: 0.5746 - val_loss: 1.6889 - val_acc: 0.2805\n",
      "\n",
      "Epoch 00110: val_acc did not improve from 0.47561\n",
      "Epoch 111/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0942 - acc: 0.5726 - val_loss: 1.5217 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00111: val_acc did not improve from 0.47561\n",
      "Epoch 112/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1047 - acc: 0.5654 - val_loss: 1.5880 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00112: val_acc did not improve from 0.47561\n",
      "Epoch 113/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1019 - acc: 0.5655 - val_loss: 1.6568 - val_acc: 0.3171\n",
      "\n",
      "Epoch 00113: val_acc did not improve from 0.47561\n",
      "Epoch 114/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0977 - acc: 0.5726 - val_loss: 1.6166 - val_acc: 0.4268\n",
      "\n",
      "Epoch 00114: val_acc did not improve from 0.47561\n",
      "Epoch 115/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0850 - acc: 0.5788 - val_loss: 1.5700 - val_acc: 0.4268\n",
      "\n",
      "Epoch 00115: val_acc did not improve from 0.47561\n",
      "Epoch 116/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0851 - acc: 0.5728 - val_loss: 1.3929 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00116: val_acc did not improve from 0.47561\n",
      "Epoch 117/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0904 - acc: 0.5700 - val_loss: 1.4768 - val_acc: 0.5122\n",
      "\n",
      "Epoch 00117: val_acc improved from 0.47561 to 0.51220, saving model to C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\1001.h5\n",
      "Epoch 118/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0950 - acc: 0.5652 - val_loss: 1.4839 - val_acc: 0.4390\n",
      "\n",
      "Epoch 00118: val_acc did not improve from 0.51220\n",
      "Epoch 119/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0999 - acc: 0.5724 - val_loss: 1.4590 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00119: val_acc did not improve from 0.51220\n",
      "Epoch 120/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0995 - acc: 0.5660 - val_loss: 1.4133 - val_acc: 0.4878\n",
      "\n",
      "Epoch 00120: val_acc did not improve from 0.51220\n",
      "Epoch 121/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1219 - acc: 0.5618 - val_loss: 1.6072 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00121: val_acc did not improve from 0.51220\n",
      "Epoch 122/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1013 - acc: 0.5701 - val_loss: 1.4580 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00122: val_acc did not improve from 0.51220\n",
      "Epoch 123/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1045 - acc: 0.5679 - val_loss: 1.6827 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00123: val_acc did not improve from 0.51220\n",
      "Epoch 124/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1050 - acc: 0.5644 - val_loss: 1.5315 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00124: val_acc did not improve from 0.51220\n",
      "Epoch 125/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0916 - acc: 0.5754 - val_loss: 1.6418 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00125: val_acc did not improve from 0.51220\n",
      "Epoch 126/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1035 - acc: 0.5651 - val_loss: 1.4861 - val_acc: 0.4390\n",
      "\n",
      "Epoch 00126: val_acc did not improve from 0.51220\n",
      "Epoch 127/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1036 - acc: 0.5677 - val_loss: 1.4265 - val_acc: 0.4512\n",
      "\n",
      "Epoch 00127: val_acc did not improve from 0.51220\n",
      "Epoch 128/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0869 - acc: 0.5745 - val_loss: 1.5036 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00128: val_acc did not improve from 0.51220\n",
      "Epoch 129/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0917 - acc: 0.5758 - val_loss: 1.5106 - val_acc: 0.4878\n",
      "\n",
      "Epoch 00129: val_acc did not improve from 0.51220\n",
      "Epoch 130/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0963 - acc: 0.5685 - val_loss: 1.4925 - val_acc: 0.4146\n",
      "\n",
      "Epoch 00130: val_acc did not improve from 0.51220\n",
      "Epoch 131/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1023 - acc: 0.5626 - val_loss: 1.6127 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00131: val_acc did not improve from 0.51220\n",
      "Epoch 132/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0939 - acc: 0.5705 - val_loss: 1.6102 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00132: val_acc did not improve from 0.51220\n",
      "Epoch 133/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0851 - acc: 0.5787 - val_loss: 1.5836 - val_acc: 0.3902\n",
      "\n",
      "Epoch 00133: val_acc did not improve from 0.51220\n",
      "Epoch 134/150\n",
      "7360/7360 [==============================] - 31s 4ms/step - loss: 1.0758 - acc: 0.5749 - val_loss: 1.7223 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00134: val_acc did not improve from 0.51220\n",
      "Epoch 135/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0818 - acc: 0.5783 - val_loss: 1.6718 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00135: val_acc did not improve from 0.51220\n",
      "Epoch 136/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0896 - acc: 0.5700 - val_loss: 1.7863 - val_acc: 0.2927\n",
      "\n",
      "Epoch 00136: val_acc did not improve from 0.51220\n",
      "Epoch 137/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0978 - acc: 0.5645 - val_loss: 1.6924 - val_acc: 0.3659\n",
      "\n",
      "Epoch 00137: val_acc did not improve from 0.51220\n",
      "Epoch 138/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0918 - acc: 0.5709 - val_loss: 1.6102 - val_acc: 0.4268\n",
      "\n",
      "Epoch 00138: val_acc did not improve from 0.51220\n",
      "Epoch 139/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0900 - acc: 0.5697 - val_loss: 1.5859 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00139: val_acc did not improve from 0.51220\n",
      "Epoch 140/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0731 - acc: 0.5776 - val_loss: 1.4477 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00140: val_acc did not improve from 0.51220\n",
      "Epoch 141/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.0869 - acc: 0.5726 - val_loss: 1.5146 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00141: val_acc did not improve from 0.51220\n",
      "Epoch 142/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0905 - acc: 0.5668 - val_loss: 1.6790 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00142: val_acc did not improve from 0.51220\n",
      "Epoch 143/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.0672 - acc: 0.5818 - val_loss: 1.6310 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00143: val_acc did not improve from 0.51220\n",
      "Epoch 144/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.0831 - acc: 0.5717 - val_loss: 1.6009 - val_acc: 0.3293\n",
      "\n",
      "Epoch 00144: val_acc did not improve from 0.51220\n",
      "Epoch 145/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.0929 - acc: 0.5671 - val_loss: 1.6875 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00145: val_acc did not improve from 0.51220\n",
      "Epoch 146/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.1040 - acc: 0.5649 - val_loss: 1.6330 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00146: val_acc did not improve from 0.51220\n",
      "Epoch 147/150\n",
      "7360/7360 [==============================] - 32s 4ms/step - loss: 1.0887 - acc: 0.5724 - val_loss: 1.5963 - val_acc: 0.3537\n",
      "\n",
      "Epoch 00147: val_acc did not improve from 0.51220\n",
      "Epoch 148/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.0999 - acc: 0.5687 - val_loss: 1.5874 - val_acc: 0.4024\n",
      "\n",
      "Epoch 00148: val_acc did not improve from 0.51220\n",
      "Epoch 149/150\n",
      "7360/7360 [==============================] - 30s 4ms/step - loss: 1.1025 - acc: 0.5738 - val_loss: 1.6298 - val_acc: 0.3780\n",
      "\n",
      "Epoch 00149: val_acc did not improve from 0.51220\n",
      "Epoch 150/150\n",
      "7360/7360 [==============================] - 29s 4ms/step - loss: 1.0815 - acc: 0.5736 - val_loss: 1.7567 - val_acc: 0.3415\n",
      "\n",
      "Epoch 00150: val_acc did not improve from 0.51220\n",
      "id : 1001\n",
      "(7360, 499, 13)\n",
      "id : 1001\n",
      "Train on 7360 samples, validate on 82 samples\n",
      "Epoch 1/150\n",
      "7328/7360 [============================>.] - ETA: 0s - loss: 1.5853 - acc: 0.3438"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-34182fdada27>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    112\u001b[0m             \u001b[0mfilePath\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34mf'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\saved_mfcc_models\\\\{i}.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcheckpoint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfilePath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'max'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msave_weights_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms0_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc0_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_num_people=[]\n",
    "for i in range(1,92):\n",
    "    if i <10:\n",
    "        total_num_people.append('100'+str(i))\n",
    "    else:\n",
    "        total_num_people.append('10'+str(i))\n",
    "\n",
    "for i in total_num_people[::-1]:\n",
    "    if int(i)<1028:\n",
    "        X_train=[]\n",
    "        X_test=[]\n",
    "        y_train=[]\n",
    "        y_test=[]\n",
    "        i=1042\n",
    "        X_train,y_train,X_test,y_test=loadData(i)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "\n",
    "    #load data here\n",
    "    #input_shape = batch_size,time_steps,input_dim\n",
    "\n",
    "    #batch_size = X_train.shape[0]   #automatically taken no need to specify\n",
    "    time_steps = X_train.shape[1]\n",
    "    input_dim = X_train.shape[2]\n",
    "\n",
    "\n",
    "\n",
    "    hid_pre_acts = [16]\n",
    "    hid_post_acts = [96]\n",
    "    #dense1s = [16,32,64,96,128,256]\n",
    "    #dense2s = [16,32,64,96,128,256]\n",
    "    for hid_pre_act in hid_pre_acts:\n",
    "        for hid_post_act in hid_post_acts:\n",
    "            # Defined shared layers as global variables\n",
    "            repeator = RepeatVector(time_steps) #500\n",
    "            concatenator = Concatenate(axis=-1)\n",
    "            densor = Dense(1, activation = \"relu\")\n",
    "            activator = Activation('softmax', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "            dotor = Dot(axes = 1)\n",
    "\n",
    "            #one step attention\n",
    "\n",
    "            def one_step_attention(a,s_prev):\n",
    "\n",
    "                s_prev = repeator(s_prev)\n",
    "                concat = concatenator([a,s_prev])\n",
    "                e = densor(concat)\n",
    "                alphas = activator(e)\n",
    "                K.print_tensor(alphas)\n",
    "                context = dotor([alphas, a])\n",
    "\n",
    "                return context\n",
    "            \n",
    "            post_activation_lstm_cell = CuDNNLSTM(hid_post_act,return_state=True)\n",
    "            #after_post_lstm  = CuDNNLSTM(16) \n",
    "            dense_softmax = Dense(6,activation='softmax')\n",
    "            conv1d1 = Conv1D(filters=96,kernel_size=2,strides=1,input_shape=(96,1),activation='relu')\n",
    "            conv1d2 = Conv1D(filters=32,kernel_size=4,strides=2,activation='relu')\n",
    "            conv1d3 = Conv1D(filters=8,kernel_size=5,strides=2,activation='relu')\n",
    "            reshape = Reshape((96,1),input_shape=(96,))\n",
    "            flatten = Flatten()\n",
    "            batchnorm = BatchNormalization()\n",
    "            #dropout = Dropout(0.4)\n",
    "                # model -----------------------------------------------------------\n",
    "\n",
    "            def model(time_steps,input_dim,hid_post_act,hid_pre_act):\n",
    "\n",
    "                X = Input(shape =(time_steps,input_dim))\n",
    "                s0 = Input(shape=(hid_post_act,),name='s0')\n",
    "                c0 = Input(shape=(hid_post_act,),name='c0')\n",
    "                s=s0\n",
    "                c=c0\n",
    "                outputs=[]\n",
    "\n",
    "\n",
    "                # Pre-LSTM 16\n",
    "                a = Bidirectional(CuDNNLSTM(hid_pre_act,return_sequences=True,))(X)\n",
    "                a = Dropout(0.4)(a)\n",
    "                a = BatchNormalization()(a)\n",
    "                #6 is final output size\n",
    "                for t in range(1):\n",
    "                    context =one_step_attention(a,s)\n",
    "                    s, _, c = post_activation_lstm_cell(context, initial_state=[s, c])\n",
    "                    s = reshape(s)\n",
    "                    s = batchnorm(s)\n",
    "                    s = conv1d1(s)\n",
    "                    s = conv1d2(s)\n",
    "                    S = conv1d3(s)\n",
    "                    s = flatten(s)\n",
    "                    s=dense_softmax(s)\n",
    "                    outputs.append(s)\n",
    "\n",
    "\n",
    "                model = Model([X, s0, c0], outputs)\n",
    "\n",
    "                return model       \n",
    "\n",
    "            model = model(time_steps,input_dim,hid_post_act,hid_pre_act)\n",
    "\n",
    "            opt = Adam()\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            #model.summary()\n",
    "            #plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "            print(X_train.shape)\n",
    "            s0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            c0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            s0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            c0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            print(f'id : {i}')\n",
    "            filePath =f'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\saved_mfcc_models\\\\{i}.h5'\n",
    "            checkpoint = ModelCheckpoint(filepath=filePath,monitor='val_acc',mode='max',save_best_only=True,verbose=1,save_weights_only=False)\n",
    "            model.fit([X_train, s0, c0], y_train, epochs=150,validation_data=([X_test,s0_t,c0_t],y_test),callbacks=[checkpoint]) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-03-24T22:57:24.998828Z",
     "start_time": "2019-03-24T22:57:16.172898Z"
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model(r\"C:\\Users\\djaym7\\Desktop\\Github\\EmotionRecognition\\saved_mfcc_models\\l\\1001.h5\")\n",
    "#model.fit([X_train, s0, c0], y_train, epochs=150,validation_data=([X_test,s0_t,c0_t],y_test),callbacks=[checkpoint]) \n",
    "y_pred = model.predict([X_test,s0_t,c0_t])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FourthModel_mfcc_bidirectional.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/djaym7/EmotionRecognition/blob/master/FourthModel.ipynb",
     "timestamp": 1553114599957
    }
   ],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
