{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (7360, 369, 20)\n",
      "X_test: (82, 369, 20)\n",
      "y_train (7360,)\n",
      "y_test (82,)\n",
      "X_train: (7360, 369, 20)\n",
      "X_test: (82, 369, 20)\n",
      "y_train (7360, 6)\n",
      "y_test (82, 6)\n",
      "(369, 20)\n",
      "(369, 20)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#get Data\n",
    "#load data from pickle\n",
    "with open('y_train','rb') as f:\n",
    "    y_train=pickle.load(f)\n",
    "with open('y_test','rb') as f:\n",
    "    y_test=pickle.load(f)\n",
    "with open('X_train','rb') as f:\n",
    "    X_train = pickle.load(f)\n",
    "with open('X_test','rb') as f:\n",
    "    X_test = pickle.load(f)\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_train',y_train.shape) \n",
    "print('y_test',y_test.shape) \n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "encoder = LabelBinarizer()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('X_test:',X_test.shape)\n",
    "print('y_train',y_train.shape) \n",
    "print('y_test',y_test.shape) \n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "#splitting dataset\n",
    "#from sklearn.model_selection import train_test_split\n",
    "#from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "X_input = X.reshape(X.shape[0], X.shape[1],1)\n",
    "#X_train,X_test,y_train,y_test = train_test_split(X_input,y,test_size=0.3)\n",
    "'''\n",
    "print(X_train[0].shape)\n",
    "print(X_test[0].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result(model,X_test,y_test):\n",
    "    #building confusion matrix\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_final=[] #getting final answers \n",
    "    y_test_final=[]\n",
    "    for i in range((y_pred.shape[0])):\n",
    "        y_pred_final.append(np.argmax(y_pred[i]))\n",
    "        y_test_final.append(np.argmax(y_test[i]))\n",
    "\n",
    "    y_pred_final_alpha=[]\n",
    "    y_test_final_alpha=[]\n",
    "\n",
    "\n",
    "    from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "    print(confusion_matrix(y_test_final,y_pred_final,labels=[0,1,2,3,4,5]))\n",
    "    labels = ['ANG','DIS','FEA','HAP','NEU','SAD']\n",
    "    print(accuracy_score(y_test_final,y_pred_final))\n",
    "\n",
    "\n",
    "    #plot confusion matrix\n",
    "    import seaborn as sn\n",
    "    import pandas as pd\n",
    "    import matplotlib.pyplot as plt\n",
    "    array = confusion_matrix(y_test_final,y_pred_final,labels=[0,1,2,3,4,5])\n",
    "    df_confusion_matrix  = pd.DataFrame(array)\n",
    "    plt.figure(figsize = (10,10))\n",
    "    plt.show()\n",
    "    sn.heatmap(df_confusion_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#simple DNN with dense layers\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import TensorBoard\n",
    "\n",
    "NAME = \"SimpleDNN\"\n",
    "tensorboard = TensorBoard(log_dir='C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\logs'.format(NAME))\n",
    "model_DNN = Sequential()\n",
    "\n",
    "model_DNN.add(Dense(units=256,input_shape=(40,)))\n",
    "model_DNN.add(Activation('relu'))\n",
    "model_DNN.add(Dropout(0.5))\n",
    "\n",
    "model_DNN.add(Dense(256))\n",
    "model_DNN.add(Activation('relu'))\n",
    "model_DNN.add(Dropout(0.5))\n",
    "\n",
    "model_DNN.add(Dense(6))\n",
    "model_DNN.add(Activation('softmax'))\n",
    "\n",
    "model_DNN.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "model_DNN.fit(X,y,epochs=10,validation_split=0.3,callbacks=[tensorboard])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#RNN changing the number of cells in RNNs\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import CuDNNLSTM,LSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "number_lstm_layers=[2,3,4]\n",
    "lstmcells = [64,128,256]\n",
    "denselayers = [32,64,128]\n",
    "\n",
    "for cell1 in lstmcells:\n",
    "    for cell2 in lstmcells:\n",
    "        for layer in denselayers:\n",
    "            \n",
    "            NAME = \"{}-Layer1-{}-Layer2-{}-dense-{}\".format(cell1,cell2,layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\logs\\\\{}'.format(NAME))\n",
    "            \n",
    "            model_RNN = Sequential()\n",
    "            model_RNN.add(CuDNNLSTM(64,input_shape=(40,1),return_sequences=True))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "\n",
    "            model_RNN.add(CuDNNLSTM(cell1,return_sequences=True))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "\n",
    "            model_RNN.add(CuDNNLSTM(cell2))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "            model_RNN.add(Dense(layer,activation='relu'))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "\n",
    "            model_RNN.add(Dense(6,activation='softmax'))\n",
    "\n",
    "            model_RNN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            model_RNN.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),callbacks=[tensorboard])\n",
    "            result(model_RNN,X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#RNN changing the number of cells in RNNs\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import CuDNNLSTM,LSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "\n",
    "lstmcells = [128,256,320]\n",
    "denselayers = [128,256]\n",
    "\n",
    "for cell1 in lstmcells:\n",
    "    for cell2 in lstmcells:\n",
    "        for layer in denselayers:\n",
    "            \n",
    "            NAME = \"{}-Layer1-{}-Layer2-{}-dense-{}\".format(cell1,cell2,layer,int(time.time()))\n",
    "            tensorboard = TensorBoard(log_dir='C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\logs\\\\{}'.format(NAME))\n",
    "            \n",
    "            model_RNN = Sequential()\n",
    "            model_RNN.add(CuDNNLSTM(64,input_shape=(40,1),return_sequences=True))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "\n",
    "            model_RNN.add(CuDNNLSTM(cell1,return_sequences=True))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "\n",
    "            model_RNN.add(CuDNNLSTM(cell2))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "            model_RNN.add(Dense(layer,activation='relu'))\n",
    "            model_RNN.add(Dropout(0.2))\n",
    "            \n",
    "\n",
    "            model_RNN.add(Dense(6,activation='softmax'))\n",
    "\n",
    "            model_RNN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "            model_RNN.fit(X_train,y_train,epochs=50,validation_data=(X_test,y_test),callbacks=[tensorboard])\n",
    "            result(model_RNN,X_test,y_test)\n",
    "# results :\n",
    "best performer 128 L1- 256 L2 - 128 Dense  93%accuracy and 75.46% val accuracy\n",
    "worst every model with 256 L1 (constant accuracy of 0.1747 and loss of 1.79 for all epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\djaym7\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7360 samples, validate on 82 samples\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
    "from tensorflow.keras.layers import CuDNNLSTM,LSTM\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import time\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()\n",
    "\n",
    "NAME = \"new-128-Layer1-256-Layer2-128-dense-{}\".format(int(time.time()))\n",
    "tensorboard = TensorBoard(log_dir='C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\logs\\\\{}'.format(NAME))\n",
    "\n",
    "model_RNN = Sequential()\n",
    "model_RNN.add(CuDNNLSTM(128,input_shape=(369,20),return_sequences=True))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model_RNN.add(CuDNNLSTM(128,return_sequences=True))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "model_RNN.add(CuDNNLSTM(128,return_sequences=True))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "model_RNN.add(CuDNNLSTM(128))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "\n",
    "model_RNN.add(Dense(128,activation='relu'))\n",
    "model_RNN.add(Dropout(0.2))\n",
    "\n",
    "\n",
    "model_RNN.add(Dense(6,activation='softmax'))\n",
    "\n",
    "model_RNN.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model_RNN.fit(X_train,y_train,epochs=30,validation_data=(X_test,y_test),callbacks=[tensorboard])\n",
    "result(model_RNN,X_test,y_test)\n",
    "\n",
    "\n",
    "#The val_accuracy never exceeded 42% while accuracy reached 7%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
