{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import pickle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.utils.vis_utils import plot_model\n",
    "\n",
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, CuDNNLSTM, Multiply,Dropout\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#address to getData->output folder\n",
    "address = \"C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\data 02\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(id):\n",
    "    with open(address + f'y_train_{id}','rb') as f:\n",
    "        y_train=np.array(pickle.load(f))\n",
    "    with open(address+f'y_test_{id}','rb') as f:\n",
    "        y_test=np.array(pickle.load(f))\n",
    "    with open(address+ f'X_train_{id}','rb') as f:\n",
    "        X_train = np.array(pickle.load(f))\n",
    "    with open(address+f'X_test_{id}','rb') as f:\n",
    "        X_test = np.array(pickle.load(f))\n",
    "\n",
    "    scalers = {}\n",
    "    for k in range(X_train.shape[2]):\n",
    "        scalers[k] = StandardScaler()\n",
    "        X_train[:, k, :] = scalers[k].fit_transform(X_train[:, k, :]) \n",
    "\n",
    "    for j in range(X_test.shape[2]):\n",
    "        X_test[:, j, :] = scalers[j].transform(X_test[:, j, :])\n",
    "    \n",
    "    print(f'id : {id}')\n",
    "    from sklearn.preprocessing import LabelBinarizer\n",
    "    encoder = LabelBinarizer()\n",
    "    y_train = encoder.fit_transform(y_train)\n",
    "    y_test = encoder.fit_transform(y_test)\n",
    "\n",
    "   \n",
    "    return X_train,y_train,X_test,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1):\n",
    "    \"\"\"\n",
    "    Plot the attention map.\n",
    "  \n",
    "    \"\"\"\n",
    "    attention_map = np.zeros((Ty, Tx))\n",
    "    Ty, Tx = attention_map.shape\n",
    "    print(attention_map.shape)\n",
    "    \n",
    "    s0 = np.zeros((X_train.shape[0], n_s))\n",
    "    c0 = np.zeros((X_train.shape[0], n_s))\n",
    "    layer = model.layers[num]\n",
    "    print('No layers','\\t',layer)\n",
    "\n",
    "\n",
    "    f = K.function(model.inputs, [layer.get_output_at(t) for t in range(Ty)])\n",
    "    r = f([X_train, s0, c0])\n",
    "    print(r)\n",
    "    \n",
    "    for t in range(Ty):\n",
    "        for t_prime in range(Tx):\n",
    "            attention_map[t][t_prime] = r[t][0,t_prime,0]\n",
    "            \n",
    "    print(attention_map)\n",
    "\n",
    "    # Normalize attention map\n",
    "#     row_max = attention_map.max(axis=1)\n",
    "#     attention_map = attention_map / row_max[:, None]\n",
    "\n",
    "    prediction = model.predict([X_train, s0, c0])\n",
    "    \n",
    " \n",
    "    \n",
    "    # get the lengths of the string\n",
    "    input_length = Tx\n",
    "    output_length = Ty\n",
    "    \n",
    "    # Plot the attention_map\n",
    "    plt.clf()\n",
    "    f = plt.figure(figsize=(8, 8.5))\n",
    "    ax = f.add_subplot(1, 1, 1)\n",
    "\n",
    "    # add image\n",
    "    i = ax.imshow(attention_map, interpolation='nearest', cmap='Blues')\n",
    "\n",
    "    # add colorbar\n",
    "    cbaxes = f.add_axes([0.2, 0, 0.6, 0.03])\n",
    "    cbar = f.colorbar(i, cax=cbaxes, orientation='horizontal')\n",
    "    cbar.ax.set_xlabel('Alpha value (Probability output of the \"softmax\")', labelpad=2)\n",
    "\n",
    "    # add labels\n",
    "    ax.set_yticks(range(output_length))\n",
    "\n",
    "    ax.set_xticks(range(input_length))\n",
    "\n",
    "    ax.set_xlabel('Input Sequence')\n",
    "    ax.set_ylabel('Output Sequence')\n",
    "\n",
    "    # add grid and legend\n",
    "    ax.grid()\n",
    "\n",
    "    #f.show()\n",
    "    \n",
    "    return attention_map\n",
    "#plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id : 1001\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 500, 13)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_12 (CuDNNLSTM)       (None, 500, 16)      1984        input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 96)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 500, 16)      0           cu_dnnlstm_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_6 (RepeatVector)  (None, 500, 96)      0           s0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 500, 112)     0           dropout_6[0][0]                  \n",
      "                                                                 repeat_vector_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_11 (Dense)                (None, 500, 1)       113         concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 500, 1)       0           dense_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dot_6 (Dot)                     (None, 1, 16)        0           attention_weights[0][0]          \n",
      "                                                                 dropout_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 96)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cu_dnnlstm_11 (CuDNNLSTM)       [(None, 96), (None,  43776       dot_6[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 6)            582         cu_dnnlstm_11[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 46,455\n",
      "Trainable params: 46,455\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "(7360, 500, 13)\n",
      "id : 1001\n",
      "Train on 7360 samples, validate on 82 samples\n",
      "Epoch 1/1\n",
      "2144/7360 [=======>......................] - ETA: 14s - loss: 1.7779 - acc: 0.2253"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-ccacd6ad8146>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    102\u001b[0m             \u001b[1;31m#filePath =f'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\ExtendedSavedModels\\\\{i}.h5'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m             \u001b[1;31m#checkpoint = ModelCheckpoint(filepath=filePath,monitor='val_acc',mode='max',save_best_only=True,verbose=1,save_weights_only=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms0_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc0_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#,callbacks=[checkpoint]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m             \u001b[1;31m#plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1037\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1038\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2664\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2665\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2666\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2667\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2668\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2634\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2635\u001b[0m                                 session)\n\u001b[1;32m-> 2636\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2637\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2638\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1382\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1383\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "total_num_people=[]\n",
    "for i in range(1,92):\n",
    "    if i <10:\n",
    "        total_num_people.append('100'+str(i))\n",
    "    else:\n",
    "        total_num_people.append('10'+str(i))\n",
    "\n",
    "for i in total_num_people:\n",
    "    if True:\n",
    "        X_train=[]\n",
    "        X_test=[]\n",
    "        y_train=[]\n",
    "        y_test=[]\n",
    "        X_train,y_train,X_test,y_test=loadData(i)\n",
    "        \n",
    "    else:\n",
    "        continue\n",
    "\n",
    "\n",
    "    #load data here\n",
    "    #input_shape = batch_size,time_steps,input_dim\n",
    "\n",
    "    #batch_size = X_train.shape[0]   #automatically taken no need to specify\n",
    "    time_steps = X_train.shape[1]\n",
    "    input_dim = X_train.shape[2]\n",
    "\n",
    "\n",
    "\n",
    "    hid_pre_acts = [16]\n",
    "    hid_post_acts = [96]\n",
    "    #dense1s = [16,32,64,96,128,256]\n",
    "    #dense2s = [16,32,64,96,128,256]\n",
    "    for hid_pre_act in hid_pre_acts:\n",
    "        for hid_post_act in hid_post_acts:\n",
    "            # Defined shared layers as global variables\n",
    "            repeator = RepeatVector(time_steps) #500\n",
    "            concatenator = Concatenate(axis=-1)\n",
    "            densor = Dense(1, activation = \"relu\")\n",
    "            activator = Activation('softmax', name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "            dotor = Dot(axes = 1)\n",
    "\n",
    "            #one step attention\n",
    "\n",
    "            def one_step_attention(a,s_prev):\n",
    "\n",
    "                s_prev = repeator(s_prev)\n",
    "                concat = concatenator([a,s_prev])\n",
    "                e = densor(concat)\n",
    "                alphas = activator(e)\n",
    "                K.print_tensor(alphas)\n",
    "                context = dotor([alphas, a])\n",
    "\n",
    "                return context\n",
    "            \n",
    "            post_activation_lstm_cell = CuDNNLSTM(hid_post_act,return_state=True)\n",
    "            #output_layer = Dense(dense1,activation='relu')\n",
    "            #onemore = Dense(dense2,activation='relu')\n",
    "            fin_out = Dense(6,activation='softmax')\n",
    "\n",
    "                # model\n",
    "\n",
    "            def model(time_steps,input_dim,hid_post_act,hid_pre_act):\n",
    "\n",
    "                X = Input(shape =(time_steps,input_dim))\n",
    "                s0 = Input(shape=(hid_post_act,),name='s0')\n",
    "                c0 = Input(shape=(hid_post_act,),name='c0')\n",
    "                s=s0\n",
    "                c=c0\n",
    "                outputs=[]\n",
    "\n",
    "\n",
    "                # Pre-LSTM 16\n",
    "                a = CuDNNLSTM(hid_pre_act,return_sequences=True)(X)\n",
    "                a = Dropout(0.4)(a)\n",
    "                #6 is final output size\n",
    "                for t in range(1):\n",
    "                    context =one_step_attention(a,s)\n",
    "                    s, _, c = post_activation_lstm_cell(context, initial_state=[s, c])\n",
    "                    #out = output_layer(s)\n",
    "                    #o = onemore(out)\n",
    "                    k=fin_out(s)\n",
    "                    outputs.append(k)\n",
    "\n",
    "\n",
    "                model = Model([X, s0, c0], outputs)\n",
    "\n",
    "                return model       \n",
    "\n",
    "            model = model(time_steps,input_dim,hid_post_act,hid_pre_act)\n",
    "\n",
    "            opt = Adam()\n",
    "            #opt = Adam(lr = 0.005, beta_1=0.9, beta_2=0.999, decay = 0.01)\n",
    "            model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "            model.summary()\n",
    "            plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "            print(X_train.shape)\n",
    "            s0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            c0 = np.zeros((X_train.shape[0], hid_post_act))\n",
    "            s0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            c0_t = np.zeros((X_test.shape[0], hid_post_act))\n",
    "            print(f'id : {i}')\n",
    "            #filePath =f'C:\\\\Users\\\\djaym7\\\\Desktop\\\\Github\\\\EmotionRecognition\\\\ExtendedSavedModels\\\\{i}.h5'\n",
    "            #checkpoint = ModelCheckpoint(filepath=filePath,monitor='val_acc',mode='max',save_best_only=True,verbose=1,save_weights_only=False)\n",
    "            model.fit([X_train, s0, c0], y_train, epochs=1,validation_data=([X_test,s0_t,c0_t],y_test)) #,callbacks=[checkpoint]\n",
    "            #plot_attention_map(model, input_dim, n_s = 96, num = 1, Tx =13 , Ty = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attention_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-a2f8763a8adb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mattention_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'attention_values' is not defined"
     ]
    }
   ],
   "source": [
    "attention_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
